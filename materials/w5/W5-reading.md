# Week 5 reading

## Spiking is not differentiable

* [Introduction to neural networks and backpropagation by 3Blue1Brown (excellent, easy to follow YouTube series)](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)

## Limited gradients

* [Julien Vitay lecture notes on reservoir computing](https://julien-vitay.net/lecturenotes-neurocomputing/4-neurocomputing/4-Reservoir.html)
* [Nicola and Clopath (2017) "Supervised learning in spiking neural networks with FORCE training"](https://doi.org/10.1038/s41467-017-01827-3)
* [Schuman et al. (2020) "Evolutionary Optimization for Neuromorphic Systems"](https://doi.org/10.1145/3381755.3381758)
* [Mitchell et al. (2017) "NeoN: Neuromorphic control for autonomous robotic navigation"](https://doi.org/10.1109/IRIS.2017.8250111)
* [Hunsberger and Eliasmith (2015) "Spiking Deep Networks with LIF Neurons"](https://arxiv.org/abs/1510.08829)
* [Neural Engineering Framework](http://compneuro.uwaterloo.ca/research/nef.html)
* [Nengo](https://www.nengo.ai/)
* [Thorpe and Imbert (1989) "Biological constraints on connectionist modelling"](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=297cd07d12ad74c10fee794fa947f02d561158ab)
* [Kheradpisheh and Masquelier (2020) "S4NN: temporal backpropagation for spiking neural networks with one spike per neuron"](https://arxiv.org/abs/1910.09495)

## Surrogate gradients

* [Neftci et al. (2019) "Surrogate Gradient Learning in Spiking Neural Networks: Bringing the Power of Gradient-Based Optimization to Spiking Neural Networks"](https://doi.org/10.1109/MSP.2019.2931595)
* [Zenke and Neftci (2021) "Brain-Inspired Learning on Neuromorphic Substrates"](https://doi.org/10.1109/JPROC.2020.3045625)
* [Zenke and Vogels (2021) "The Remarkable Robustness of Surrogate Gradient Learning for Instilling Complex Function in Spiking Neural Networks"](https://doi.org/10.1162/neco_a_01367)
* [SPyTorch tutorial (including video)](https://github.com/fzenke/spytorch)
* [Spiking Heidelberg Digits dataset](https://zenkelab.org/resources/spiking-heidelberg-datasets-shd/)
* [Lillicrap and Santoro (2019) "Backpropagation through time and the brain"](https://doi.org/10.1016/j.conb.2019.01.011)
* [Rossbroich et al. (2022) "Fluctuation-driven initialization for spiking neural network training"](https://iopscience.iop.org/article/10.1088/2634-4386/ac97bb/meta)
* [Perez-Nieves et al. (2023) "Spiking Network Initialisation and Firing Rate Collapse"](https://arxiv.org/abs/2305.08879)
* [Perez-Nieves et al. (2021) "Neural heterogeneity promotes robust learning"](https://doi.org/10.1038/s41467-021-26022-3)

## Approximate gradients

* [Marschall et al. (2019) "A Unified Framework of Online Learning Algorithms for Training Recurrent Neural Networks"](https://arxiv.org/abs/1907.02649)
